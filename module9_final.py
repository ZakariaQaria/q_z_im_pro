import streamlit as st
import cv2
import numpy as np
import os
from helpers import load_image, add_user_progress
from achievements import add_achievement

def show_module9():
    """Ø¹Ø±Ø¶ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø§Ù„ØªØ§Ø³Ø¹Ø©: Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø®ØªØ§Ù…ÙŠ"""
    
    st.header("ğŸ“ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© 9: Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø®ØªØ§Ù…ÙŠ")
    
    # Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„ØªÙ‚Ø¯Ù…
    if st.session_state.progress.get("module9", False):
        st.success("âœ… Ù„Ù‚Ø¯ Ø£ÙƒÙ…Ù„Øª Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø¨Ø§Ù„ÙØ¹Ù„")
    else:
        if add_user_progress("module9"):
            st.balloons()
            st.success("ğŸ‰ Ù…Ø¨Ø±ÙˆÙƒ! Ù„Ù‚Ø¯ Ø£ÙƒÙ…Ù„Øª Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø© Ø§Ù„ØªØ§Ø³Ø¹Ø© ÙˆØ­ØµÙ„Øª Ø¹Ù„Ù‰ 20 Ù†Ù‚Ø·Ø©")
            add_achievement("Ø®Ø¨ÙŠØ± Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±", "Ø¥ÙƒÙ…Ø§Ù„ Ø¬Ù…ÙŠØ¹ Ù…Ø­Ø§Ø¶Ø±Ø§Øª Ø§Ù„Ø¯ÙˆØ±Ø©")
    
    # Ø§Ù„Ù†Ø¸Ø±ÙŠØ©
    with st.expander("ğŸ“– Ù†Ø¸Ø±Ø© Ø¹Ø§Ù…Ø©", expanded=True):
        st.markdown("""
        ## Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø®ØªØ§Ù…ÙŠ: ØªØ·Ø¨ÙŠÙ‚ Ø¹Ù…Ù„ÙŠ Ù…ØªÙƒØ§Ù…Ù„
        
        ÙÙŠ Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø©ØŒ Ø³ØªØ·Ø¨Ù‚ ÙƒÙ„ Ù…Ø§ ØªØ¹Ù„Ù…ØªÙ‡ ÙÙŠ Ø§Ù„Ù…Ø­Ø§Ø¶Ø±Ø§Øª Ø§Ù„Ø³Ø§Ø¨Ù‚Ø© Ù„Ø¨Ù†Ø§Ø¡ pipeline ÙƒØ§Ù…Ù„ Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±.
        
        ### ğŸ¯ Ø§Ù„Ù…ÙŠØ²Ø§Øª Ø§Ù„Ù…ØªÙˆÙØ±Ø©:
        - âœ… Ø±ÙØ¹ Ø§Ù„ØµÙˆØ± Ù…Ù† Ø§Ù„Ø¬Ù‡Ø§Ø²
        - âœ… Ø§Ø®ØªÙŠØ§Ø± Ø³Ù„Ø³Ù„Ø© Ø¹Ù…Ù„ÙŠØ§Øª Ù…ØªÙƒØ§Ù…Ù„Ø©
        - âœ… Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø© Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©
        - âœ… Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø¨Ù…Ù‚Ø§Ø±Ù†Ø© Ù‚Ø¨Ù„/Ø¨Ø¹Ø¯
        - âœ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ø§ØªØ¬Ø©
        - âœ… ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬
        """)
    
    st.markdown("---")
    
    # Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠ
    st.subheader("ğŸ”§ Ø§Ù„Ù…Ø´Ø±ÙˆØ¹ Ø§Ù„Ø¹Ù…Ù„ÙŠ: Ø¨Ù†Ø§Ø¡ Pipeline Ù…ØªÙƒØ§Ù…Ù„")
    
    # ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©
    st.markdown("#### ğŸ“¤ Ø§Ù„Ø®Ø·ÙˆØ© 1: ØªØ­Ù…ÙŠÙ„ Ø§Ù„ØµÙˆØ±Ø©")
    uploaded_file = st.file_uploader("Ø§Ø®ØªØ± ØµÙˆØ±Ø© Ù„Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", type=['jpg', 'jpeg', 'png'], key="final_upload")
    
    if uploaded_file is not None:
        original_image = load_image(uploaded_file)
        st.image(original_image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)
    else:
        # Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ©
        original_image = create_final_project_sample()
        st.image(original_image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø§ÙØªØ±Ø§Ø¶ÙŠØ©", use_container_width=True)
    
    if original_image is not None:
        st.markdown("---")
        st.markdown("#### âš™ï¸ Ø§Ù„Ø®Ø·ÙˆØ© 2: Ø¨Ù†Ø§Ø¡ Pipeline Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©")
        
        # Ø£Ù…Ø«Ù„Ø© Ø¹Ù„Ù‰ Ø³Ù„Ø§Ø³Ù„ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø©
        st.markdown("##### ğŸ¯ Ø£Ù…Ø«Ù„Ø© Ø¬Ø§Ù‡Ø²Ø©:")
        
        preset_options = {
            "ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ + ØªÙ…ÙˆÙŠÙ‡ + Ø­ÙˆØ§Ù": ["convert_grayscale", "remove_noise", "detect_edges"],
            "ØªØ­Ø³ÙŠÙ† ØªØ¨Ø§ÙŠÙ† + ÙƒØ´Ù Ø­ÙˆØ§Ù": ["adjust_contrast", "detect_edges"],
            "Ø¥Ø²Ø§Ù„Ø© Ø¶ÙˆØ¶Ø§Ø¡ + ØªØ­Ø³ÙŠÙ†": ["remove_noise", "adjust_contrast"],
            "ÙƒØ´Ù Ø­ÙˆØ§Ù Ù…ØªÙ‚Ø¯Ù…": ["convert_grayscale", "remove_noise", "detect_edges", "apply_morphology"]
        }
        
        selected_preset = st.selectbox("Ø§Ø®ØªØ± pipeline Ø¬Ø§Ù‡Ø²:", list(preset_options.keys()))
        
        # ØªØ·Ø¨ÙŠÙ‚ Ø§Ù„Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ø§Ù„Ø¬Ø§Ù‡Ø²Ø©
        if selected_preset:
            preset_settings = preset_options[selected_preset]
            convert_grayscale = "convert_grayscale" in preset_settings
            adjust_contrast = "adjust_contrast" in preset_settings
            remove_noise = "remove_noise" in preset_settings
            detect_edges = "detect_edges" in preset_settings
            apply_morphology = "apply_morphology" in preset_settings
        else:
            convert_grayscale = False
            adjust_contrast = False
            remove_noise = False
            detect_edges = False
            apply_morphology = False
        
        st.markdown("##### âš™ï¸ ØªØ¹Ø¯ÙŠÙ„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª Ù…Ø®ØµØµØ©:")
        
        col1, col2 = st.columns(2)
        
        with col1:
            convert_grayscale = st.checkbox("ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ", value=convert_grayscale)
            adjust_contrast = st.checkbox("Ø¶Ø¨Ø· Ø§Ù„ØªØ¨Ø§ÙŠÙ†", value=adjust_contrast)
            remove_noise = st.checkbox("Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡", value=remove_noise)
        
        with col2:
            detect_edges = st.checkbox("ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù", value=detect_edges)
            apply_morphology = st.checkbox("Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©", value=apply_morphology)
            add_overlay = st.checkbox("Ø¥Ø¶Ø§ÙØ© overlay Ø¹Ù„Ù‰ Ø§Ù„Ø­ÙˆØ§Ù", value=False)
        
        # Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ø§Ù„ØªØ­ÙƒÙ…
        st.markdown("##### âš–ï¸ Ø¶Ø¨Ø· Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª:")
        
        col1, col2, col3 = st.columns(3)
        
        with col1:
            contrast_level = st.slider("Ù…Ø³ØªÙˆÙ‰ Ø§Ù„ØªØ¨Ø§ÙŠÙ†", 0.5, 3.0, 1.2, 0.1)
            noise_level = st.slider("Ù‚ÙˆØ© Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡", 1, 15, 5)
        
        with col2:
            edge_threshold = st.slider("Ø¹ØªØ¨Ø© Ø§Ù„Ø­ÙˆØ§Ù", 50, 200, 100)
            morph_size = st.slider("Ø­Ø¬Ù… Ø§Ù„Ù†ÙˆØ§Ø©", 1, 10, 3)
        
        with col3:
            overlay_opacity = st.slider("Ø´ÙØ§ÙÙŠØ© Ø§Ù„Ù€ Overlay", 0.0, 1.0, 0.5, 0.1)
            transform_angle = st.slider("Ø²Ø§ÙˆÙŠØ© Ø§Ù„Ø¯ÙˆØ±Ø§Ù†", -30, 30, 0)
        
        # Ø²Ø± Ø§Ù„ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠ
        if st.button("ğŸš€ ØªØ´ØºÙŠÙ„ Pipeline", type="primary", use_container_width=True):
            with st.spinner("Ø¬Ø§Ø±ÙŠ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±Ø©..."):
                # ØªØ·Ø¨ÙŠÙ‚ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©
                processed_image = original_image.copy()
                steps_log = []
                intermediate_results = []
                
                # 1. ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ
                if convert_grayscale:
                    if len(processed_image.shape) == 3:
                        processed_image = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                    steps_log.append("âœ… ØªØ­ÙˆÙŠÙ„ Ø¥Ù„Ù‰ ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ")
                    intermediate_results.append(("ØªØ¯Ø±Ø¬ Ø±Ù…Ø§Ø¯ÙŠ", processed_image.copy()))
                
                # 2. Ø¶Ø¨Ø· Ø§Ù„ØªØ¨Ø§ÙŠÙ†
                if adjust_contrast:
                    if len(processed_image.shape) == 2:
                        processed_image = cv2.convertScaleAbs(processed_image, alpha=contrast_level, beta=0)
                    else:
                        processed_image = cv2.convertScaleAbs(processed_image, alpha=contrast_level, beta=0)
                    steps_log.append(f"âœ… Ø¶Ø¨Ø· Ø§Ù„ØªØ¨Ø§ÙŠÙ† (Ù…Ø³ØªÙˆÙ‰: {contrast_level})")
                    intermediate_results.append(("Ø¨Ø¹Ø¯ Ø§Ù„ØªØ¨Ø§ÙŠÙ†", processed_image.copy()))
                
                # 3. Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ - Ø§Ù„Ø¥ØµÙ„Ø§Ø­ Ù‡Ù†Ø§
                if remove_noise:
                    # ØªØ£ÙƒØ¯ Ø£Ù† Ø­Ø¬Ù… kernel ÙØ±Ø¯ÙŠ
                    kernel_size = noise_level
                    if kernel_size % 2 == 0:  # Ø¥Ø°Ø§ ÙƒØ§Ù† Ø²ÙˆØ¬ÙŠ
                        kernel_size += 1      # Ø§Ø¬Ø¹Ù„Ù‡ ÙØ±Ø¯ÙŠ
                    
                    processed_image = cv2.medianBlur(processed_image, kernel_size)
                    steps_log.append(f"âœ… Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡ (Ù‚ÙˆØ©: {kernel_size})")
                    intermediate_results.append(("Ø¨Ø¹Ø¯ Ø¥Ø²Ø§Ù„Ø© Ø§Ù„Ø¶ÙˆØ¶Ø§Ø¡", processed_image.copy()))
                
                # 4. ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù
                edges = None
                if detect_edges:
                    if len(processed_image.shape) == 3:
                        gray = cv2.cvtColor(processed_image, cv2.COLOR_BGR2GRAY)
                    else:
                        gray = processed_image
                    edges = cv2.Canny(gray, edge_threshold, edge_threshold * 2)
                    steps_log.append(f"âœ… ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù (Ø¹ØªØ¨Ø©: {edge_threshold})")
                    intermediate_results.append(("ÙƒØ´Ù Ø§Ù„Ø­ÙˆØ§Ù", edges.copy()))
                
                # 5. Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©
                if apply_morphology and edges is not None:
                    kernel = np.ones((morph_size, morph_size), np.uint8)
                    edges = cv2.morphologyEx(edges, cv2.MORPH_CLOSE, kernel)
                    steps_log.append(f"âœ… Ø¹Ù…Ù„ÙŠØ§Øª Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ© (Ø­Ø¬Ù…: {morph_size}x{morph_size})")
                    intermediate_results.append(("Ø¨Ø¹Ø¯ Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø§Ù„Ù…ÙˆØ±ÙÙˆÙ„ÙˆØ¬ÙŠØ©", edges.copy()))
                
                # 6. Ø¥Ø¶Ø§ÙØ© overlay Ù„Ù„Ø­ÙˆØ§Ù
                result_image = original_image.copy()
                if add_overlay and edges is not None:
                    if len(result_image.shape) == 2:
                        result_image = cv2.cvtColor(result_image, cv2.COLOR_GRAY2BGR)
                    
                    # Ø¥Ù†Ø´Ø§Ø¡ overlay Ø£Ø­Ù…Ø± Ù„Ù„Ø­ÙˆØ§Ù
                    overlay = result_image.copy()
                    overlay[edges > 0] = [0, 0, 255]  # Ø£Ø­Ù…Ø±
                    result_image = cv2.addWeighted(overlay, overlay_opacity, result_image, 1 - overlay_opacity, 0)
                    steps_log.append(f"âœ… Ø¥Ø¶Ø§ÙØ© overlay Ù„Ù„Ø­ÙˆØ§Ù (Ø´ÙØ§ÙÙŠØ©: {overlay_opacity})")
                    intermediate_results.append(("Ø¨Ø¹Ø¯ Ø¥Ø¶Ø§ÙØ© Overlay", result_image.copy()))
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ù†ØªØ§Ø¦Ø¬
                st.markdown("---")
                st.markdown("#### ğŸ“Š Ø§Ù„Ù†ØªØ§Ø¦Ø¬ Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©")
                
                col1, col2 = st.columns(2)
                
                with col1:
                    st.image(original_image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ø£ØµÙ„ÙŠØ©", use_container_width=True)
                
                with col2:
                    if 'result_image' in locals() and result_image is not None:
                        st.image(result_image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„Ù†Ù‡Ø§Ø¦ÙŠØ©", use_container_width=True)
                    elif edges is not None:
                        st.image(edges, caption="Ø§Ù„Ø­ÙˆØ§Ù Ø§Ù„Ù…ÙƒØªØ´ÙØ©", use_container_width=True)
                    else:
                        st.image(processed_image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©", use_container_width=True)
                
                # Ø¹Ø±Ø¶ Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…ØªÙˆØ³Ø·Ø©
                if len(intermediate_results) > 1:
                    st.markdown("#### ğŸ” Ø§Ù„Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…ØªÙˆØ³Ø·Ø©")
                    cols = st.columns(len(intermediate_results))
                    for idx, (step_name, step_image) in enumerate(intermediate_results):
                        with cols[idx]:
                            st.image(step_image, caption=step_name, use_container_width=True)
                
                # Ø¹Ø±Ø¶ Ø³Ø¬Ù„ Ø§Ù„Ø®Ø·ÙˆØ§Øª
                st.markdown("#### ğŸ“ Ø³Ø¬Ù„ Ø®Ø·ÙˆØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
                for step in steps_log:
                    st.write(f"â€¢ {step}")
                
                # Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª
                st.markdown("#### ğŸ“ˆ Ø¥Ø­ØµØ§Ø¦ÙŠØ§Øª Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©:")
                
                col1, col2, col3 = st.columns(3)
                
                with col1:
                    if edges is not None:
                        edge_pixels = np.sum(edges > 0)
                        st.metric("Ø¨ÙƒØ³Ù„Ø§Øª Ø§Ù„Ø­ÙˆØ§Ù", f"{edge_pixels:,}")
                
                with col2:
                    processing_time = len(steps_log) * 0.3
                    st.metric("Ø§Ù„ÙˆÙ‚Øª Ø§Ù„ØªÙ‚Ø¯ÙŠØ±ÙŠ", f"{processing_time:.1f} Ø«Ø§Ù†ÙŠØ©")
                
                with col3:
                    if 'result_image' in locals():
                        img_size = result_image.nbytes / 1024
                    else:
                        img_size = processed_image.nbytes / 1024
                    st.metric("Ø­Ø¬Ù… Ø§Ù„ØµÙˆØ±Ø©", f"{img_size:.1f} ÙƒÙŠÙ„ÙˆØ¨Ø§ÙŠØª")
                
                # Ø²Ø± Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ø§ØªØ¬Ø©
                st.markdown("---")
                st.markdown("#### ğŸ’¾ Ø­ÙØ¸ Ø§Ù„Ù†ØªÙŠØ¬Ø©")
                
                # Ø¥Ù†Ø´Ø§Ø¡ Ø²Ø± Ø§Ù„Ø­ÙØ¸
                col1, col2 = st.columns(2)
                
                with col1:
                    if st.button("ğŸ’¾ Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù†Ø§ØªØ¬Ø©", type="secondary", use_container_width=True):
                        try:
                            # ØªØ­Ø¯ÙŠØ¯ Ø§Ù„ØµÙˆØ±Ø© Ù„Ù„Ø­ÙØ¸
                            if 'result_image' in locals() and result_image is not None:
                                image_to_save = result_image
                            elif edges is not None:
                                image_to_save = edges
                            else:
                                image_to_save = processed_image
                            
                            # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø£Ù„ÙˆØ§Ù† Ø¥Ø°Ø§ needed
                            if len(image_to_save.shape) == 3:
                                image_to_save = cv2.cvtColor(image_to_save, cv2.COLOR_RGB2BGR)
                            
                            # Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©
                            success = cv2.imwrite("processed_image.jpg", image_to_save)
                            
                            if success:
                                st.success("âœ… ØªÙ… Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø© Ø¨Ù†Ø¬Ø§Ø­!")
                                st.info("ğŸ“ Ø§Ù„Ù…Ù„Ù: processed_image.jpg")
                                
                                # Ø¹Ø±Ø¶ ØµÙˆØ±Ø© Ù…ØµØºØ±Ø©
                                try:
                                    saved_image = cv2.imread("processed_image.jpg")
                                    if saved_image is not None:
                                        if len(saved_image.shape) == 3:
                                            saved_image = cv2.cvtColor(saved_image, cv2.COLOR_BGR2RGB)
                                        st.image(saved_image, caption="Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©", width=300)
                                except Exception as e:
                                    st.warning("âš ï¸ Ù„Ø§ ÙŠÙ…ÙƒÙ† Ø¹Ø±Ø¶ Ø§Ù„ØµÙˆØ±Ø© Ø§Ù„Ù…Ø­ÙÙˆØ¸Ø©")
                            else:
                                st.error("âŒ ÙØ´Ù„ ÙÙŠ Ø­ÙØ¸ Ø§Ù„ØµÙˆØ±Ø©")
                                
                        except Exception as e:
                            st.error(f"âŒ Ø®Ø·Ø£ ÙÙŠ Ø§Ù„Ø­ÙØ¸: {str(e)}")
                
                with col2:
                    # Ø²Ø± ØªØ­Ù…ÙŠÙ„ Ø¥Ø¶Ø§ÙÙŠ
                    if os.path.exists("processed_image.jpg"):
                        with open("processed_image.jpg", "rb") as file:
                            st.download_button(
                                label="â¬‡ï¸ ØªØ­Ù…ÙŠÙ„ Ø§Ù„Ù…Ù„Ù",
                                data=file,
                                file_name="ØµÙˆØ±ØªÙŠ_Ø§Ù„Ù…Ø¹Ø§Ù„Ø¬Ø©.jpg",
                                mime="image/jpeg",
                                use_container_width=True
                            )
    
    st.markdown("---")
    
    # Ù‚Ø³Ù… Ø§Ù„ØªØ­Ø¯ÙŠ Ø§Ù„Ø¥Ø¨Ø¯Ø§Ø¹ÙŠ
    st.subheader("ğŸ¨ ØªØµÙ…ÙŠÙ… Pipeline Ù…Ø®ØµØµ")
    
    st.markdown("""
    ### ğŸš€ ØµÙ…Ù… pipeline Ø®Ø§Øµ Ø¨Ùƒ:
    - Ø§Ø®ØªØ§Ø± Ø§Ù„ØªÙ‚Ù†ÙŠØ§Øª Ø§Ù„Ù…Ù†Ø§Ø³Ø¨Ø© Ù„Ù…Ø´Ø±ÙˆØ¹Ùƒ
    - Ø¶Ø¨Ø· Ø§Ù„Ù…Ø¹Ø§Ù…Ù„Ø§Øª Ù„Ù„Ø­ØµÙˆÙ„ Ø¹Ù„Ù‰ Ø£ÙØ¶Ù„ Ù†ØªÙŠØ¬Ø©
    - Ø§Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙˆØ´Ø§Ø±ÙƒÙ‡Ø§
    """)

def create_final_project_sample():
    """Ø¥Ù†Ø´Ø§Ø¡ ØµÙˆØ±Ø© Ø§ÙØªØ±Ø§Ø¶ÙŠØ© Ù„Ù„Ù…Ø´Ø±ÙˆØ¹"""
    image = np.zeros((400, 500, 3), dtype=np.uint8)
    
    # Ø®Ù„ÙÙŠØ© Ù…ØªØ¯Ø±Ø¬Ø©
    for i in range(500):
        color = int(255 * i / 500)
        image[:, i] = [color, color//2, 255-color]
    
    # Ø¥Ø¶Ø§ÙØ© Ø£Ø´ÙƒØ§Ù„ Ù…Ø®ØªÙ„ÙØ©
    cv2.rectangle(image, (50, 50), (150, 150), (0, 0, 255), -1)  # Ø£Ø­Ù…Ø±
    cv2.circle(image, (400, 100), 60, (0, 255, 0), -1)  # Ø£Ø®Ø¶Ø±
    cv2.rectangle(image, (250, 250), (350, 350), (255, 0, 0), -1)  # Ø£Ø²Ø±Ù‚
    
    # Ø¥Ø¶Ø§ÙØ© Ù†Øµ
    font = cv2.FONT_HERSHEY_SIMPLEX
    cv2.putText(image, 'Ù…Ø´Ø±ÙˆØ¹ Ù…Ø¹Ø§Ù„Ø¬Ø© Ø§Ù„ØµÙˆØ±', (100, 380), font, 1, (255, 255, 255), 3, cv2.LINE_AA)
    
    return image